{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nobce\\OneDrive\\Documentos\\PRUEBA CIENCITIFICO DATOS\\PUNTO_1\n"
     ]
    }
   ],
   "source": [
    "# PNL DIPLOMACY\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import precision_recall_fscore_support, f1_score\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "def load_jsonl(file_path):\n",
    "    data = []\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            for line in file:\n",
    "                data.append(json.loads(line))\n",
    "    except FileNotFoundError:\n",
    "        print(f\"El archivo {file_path} no se encuentra.\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error al decodificar JSON en el archivo {file_path}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Se produjo un error: {e}\")\n",
    "    return data\n",
    "\n",
    "# Ruta en la que deseas buscar el archivo\n",
    "search_path = os.getcwd()  # Directorio de trabajo actual\n",
    "print(search_path)\n",
    "\n",
    "#Cargando los .json\n",
    "train_data = load_jsonl(r'data/train.jsonl')\n",
    "test_data = load_jsonl(r'data/test.jsonl')\n",
    "validation_data = load_jsonl(r'data/validation.jsonl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#función para extraer columna mensaje y etiquetas que son mis parametros de entrada\n",
    "def extract_messages_and_labels(data):\n",
    "    messages = []\n",
    "    labels = []\n",
    "    for game in data:\n",
    "        for message, label in zip(game['messages'], game['sender_labels']):\n",
    "            messages.append(message)\n",
    "            labels.append(int(label))\n",
    "    return messages, labels\n",
    "\n",
    "#parametros de entrada\n",
    "#Extrae mensajes y etiquetas\n",
    "train_messages, train_labels = extract_messages_and_labels(train_data)\n",
    "val_messages, val_labels = extract_messages_and_labels(validation_data)\n",
    "test_messages, test_labels = extract_messages_and_labels(test_data)\n",
    "\n",
    "\n",
    "#Se crean los DataFrames\n",
    "train_df = pd.DataFrame({'message': train_messages, 'label': train_labels})\n",
    "val_df = pd.DataFrame({'message': val_messages, 'label': val_labels})\n",
    "test_df = pd.DataFrame({'message': test_messages, 'label': test_labels})\n",
    "\n",
    "\n",
    "# EDA - Análisis Exploratorio de Datos\n",
    "# Imprimir información sobre los datos\n",
    "print(f\"Tamaño conjunto de entrenamiento: {len(train_df)}\")\n",
    "print(f\"Tamaño conjunto de prueba: {len(test_df)}\")\n",
    "print(f\"Tamaño conjunto de validación: {len(val_df)}\")\n",
    "print(f\"Distribución de etiquetas en el conjunto de entrenamiento:\")\n",
    "print(train_df['label'].value_counts(normalize=True))\n",
    "\n",
    "# Gráfico de barras de la distribución de etiquetas\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='label', data=train_df)\n",
    "plt.title('Distribución de etiquetas en el conjunto de entrenamiento')\n",
    "plt.xlabel('Etiqueta')\n",
    "plt.ylabel('Recuento')\n",
    "plt.show()\n",
    "\n",
    "#Longitud promedio de los mensajes\n",
    "train_df['message_length'] = train_df['message'].apply(len)\n",
    "test_df['message_length'] = test_df['message'].apply(len)\n",
    "val_df['message_length'] = val_df['message'].apply(len)\n",
    "print(f\"Longitud promedio de los mensajes en el conjunto de train: {train_df['message_length'].mean():.2f}\")\n",
    "print(f\"Longitud promedio de los mensajes en el conjunto test: {test_df['message_length'].mean():.2f}\")\n",
    "print(f\"Longitud promedio de los mensajes en el conjunto de val: {val_df['message_length'].mean():.2f}\")\n",
    "\n",
    "# Gráfico de distribución de longitud de mensajes\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(data=train_df, x='message_length', bins=30, kde=True)\n",
    "plt.title('Distribución de longitud de mensajes en el conjunto de entrenamiento')\n",
    "plt.xlabel('Longitud del mensaje')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descargando las palabras stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Obtener las palabras de parada en inglés\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Función para eliminar las palabras de parada de un mensaje\n",
    "def remove_stopwords(message):\n",
    "    words = message.lower().split()\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "\n",
    "\n",
    "#Longitud promedio de los mensajes\n",
    "train_df['message_length'] = train_df['message'].apply(len)\n",
    "test_df['message_length'] = test_df['message'].apply(len)\n",
    "val_df['message_length'] = val_df['message'].apply(len)\n",
    "print(f\"Longitud promedio de los mensajes en el conjunto de train: {train_df['message_length'].mean():.2f}\")\n",
    "print(f\"Longitud promedio de los mensajes en el conjunto test: {test_df['message_length'].mean():.2f}\")\n",
    "print(f\"Longitud promedio de los mensajes en el conjunto de val: {val_df['message_length'].mean():.2f}\")\n",
    "\n",
    "\n",
    "# Eliminar las palabras de parada de los mensajes en train_df\n",
    "train_df['message_filtered'] = train_df['message'].apply(remove_stopwords)\n",
    "\n",
    "# Eliminar las palabras de parada de los mensajes en test_df\n",
    "test_df['message_filtered'] = test_df['message'].apply(remove_stopwords)\n",
    "\n",
    "# Eliminar las palabras de parada de los mensajes en val_df\n",
    "val_df['message_filtered'] = val_df['message'].apply(remove_stopwords)\n",
    "\n",
    "#Longitud promedio de los mensajes\n",
    "train_df['message_length'] = train_df['message_filtered'].apply(len)\n",
    "test_df['message_length'] = test_df['message_filtered'].apply(len)\n",
    "val_df['message_length'] = val_df['message_filtered'].apply(len)\n",
    "\n",
    "print(\"\\nLongitud promedio de los mensajes despues de eliminar las palabras stopwords\\n\")\n",
    "print(f\"Longitud promedio de los mensajes en el conjunto de train: {train_df['message_length'].mean():.2f}\")\n",
    "print(f\"Longitud promedio de los mensajes en el conjunto test: {test_df['message_length'].mean():.2f}\")\n",
    "print(f\"Longitud promedio de los mensajes en el conjunto de val: {val_df['message_length'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar si CUDA está disponible y seleccionar el dispositivo\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if device.type == 'cuda':\n",
    "    print(\"Usando GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"Usando CPU\")\n",
    "\n",
    "# Mover el modelo a CPU si no hay suficiente memoria en GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el tokenizador y el modelo pre-entrenado de BERT\n",
    "#tokenizer = BertTokenizer.from_pretrained(ruta_raiz + r'\\bert-master')\n",
    "#bert_model = BertModel.from_pretrained(ruta_raiz + r'\\bert-master')\n",
    "\n",
    "\n",
    "#Cargar el tokenizador y el modelo pre-entrenado de BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "bert_model.to(device)\n",
    "\n",
    "# Mover el modelo a CPU si no hay suficiente memoria en GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "bert_model.to(device)\n",
    "\n",
    "#procesa los datos en lotes más pequeños para evitar problemas de memoria\n",
    "def get_embeddings(df, batch_size=32):\n",
    "    embeddings = []\n",
    "    for i in tqdm(range(0, len(df), batch_size)):\n",
    "        batch = df['message_filtered'].iloc[i:i+batch_size].tolist()\n",
    "        encodings = tokenizer(batch, truncation=True, padding=True, return_tensors='pt')\n",
    "        \n",
    "        # Mover los tensores al dispositivo adecuado\n",
    "        input_ids = encodings['input_ids'].to(device)\n",
    "        attention_mask = encodings['attention_mask'].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = bert_model(input_ids, attention_mask=attention_mask)\n",
    "            batch_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "        \n",
    "        embeddings.append(batch_embeddings)\n",
    "    \n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "# Obtener embeddings para cada conjunto de datos\n",
    "print(\"Procesando embeddings del conjunto de train...\")\n",
    "train_embeddings = get_embeddings(train_df)\n",
    "\n",
    "print(\"Procesando embeddings del conjunto de test...\")\n",
    "test_embeddings = get_embeddings(test_df)\n",
    "\n",
    "print(\"Procesando embeddings del conjunto de validación...\")\n",
    "val_embeddings = get_embeddings(val_df)\n",
    "\n",
    "# Aplicar SMOTE para sobremuestreo en el conjunto de entrenamiento\n",
    "print(\"Aplicando SMOTE...\")\n",
    "smote = SMOTE(random_state=42)\n",
    "train_embeddings_resampled, train_labels_resampled = smote.fit_resample(train_embeddings, train_df['label'])\n",
    "\n",
    "print(\"Procesamiento completado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings_resampled.shape, train_labels_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TSNE es una técnica de reducción de dimensionalidad que se utiliza para visualizar datos de alta dimensión en un espacio de menor dimensión\n",
    "def plot_embeddings(embeddings, labels, title):\n",
    "    # Reducir dimensionalidad con t-SNE\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    reduced_embeddings = tsne.fit_transform(embeddings)\n",
    "    \n",
    "    # Crear un DataFrame para facilitar la visualización\n",
    "    df = pd.DataFrame({\n",
    "        'x': reduced_embeddings[:, 0],\n",
    "        'y': reduced_embeddings[:, 1],\n",
    "        'label': labels\n",
    "    })\n",
    "    \n",
    "    # Crear el gráfico\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.scatterplot(data=df, x='x', y='y', hue='label', palette='deep')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Visualizar embeddings originales\n",
    "plot_embeddings(train_embeddings, train_df['label'], \"Distribución de embeddings originales\")\n",
    "\n",
    "# Visualizar embeddings después de SMOTE\n",
    "plot_embeddings(train_embeddings_resampled, train_labels_resampled, \"Distribución de embeddings después de SMOTE\")\n",
    "\n",
    "# Analizar la distribución de clases\n",
    "print(\"Distribución de clases original:\")\n",
    "print(pd.Series(train_df['label']).value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nDistribución de clases después de SMOTE:\")\n",
    "print(pd.Series(train_labels_resampled).value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir los embeddings y etiquetas a tensores de PyTorch\n",
    "# Datos de entrenamiento (ya balanceados con SMOTE)\n",
    "train_embeddings = torch.FloatTensor(train_embeddings_resampled)\n",
    "train_labels = torch.LongTensor(train_labels_resampled)\n",
    "\n",
    "# Datos de validación\n",
    "val_embeddings = torch.FloatTensor(val_embeddings)  #messages embeddings\n",
    "val_labels = torch.LongTensor(val_labels)\n",
    "\n",
    "# Datos de prueba\n",
    "test_embeddings = torch.FloatTensor(test_embeddings)\n",
    "test_labels = torch.LongTensor(test_labels)\n",
    "\n",
    "# Crear datasets\n",
    "# Un TensorDataset combina los embeddings con sus etiquetas correspondientes\n",
    "train_dataset = TensorDataset(train_embeddings, train_labels)\n",
    "val_dataset = TensorDataset(val_embeddings, val_labels)\n",
    "test_dataset = TensorDataset(test_embeddings, test_labels)\n",
    "\n",
    "# Crear dataloaders\n",
    "# Los DataLoaders permiten cargar los datos en lotes (batches) durante el entrenamiento y evaluación\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el modelo\n",
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.layer2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer1(x))\n",
    "        return self.layer2(x)\n",
    "\n",
    "# Inicializar el modelo\n",
    "input_dim = train_embeddings.shape[1]  # Dimensión de los embeddings de BERT\n",
    "hidden_dim = 128 #256 # numero de neuronas en la capa oculta\n",
    "output_dim = 2  # Binario: mentira o no mentira\n",
    "model = BERTClassifier(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Usar las etiquetas después de SMOTE para los pesos\n",
    "train_labels_np = train_labels_resampled.cpu().numpy() if isinstance(train_labels_resampled, torch.Tensor) else np.array(train_labels_resampled)\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(train_labels_np), y=train_labels_np)\n",
    "class_weights = torch.FloatTensor(class_weights).to(device)\n",
    "\n",
    "\n",
    "# Ajustar los pesos manualmente\n",
    "adjustment_factor = 1.5  # Dar 50% más de peso a la clase 1\n",
    "class_weights[1] *= adjustment_factor\n",
    "\n",
    "# Normalizar los pesos para que sumen 1\n",
    "class_weights /= class_weights.sum()\n",
    "\n",
    "# Actualizar el criterio con los pesos calculados\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-5 , weight_decay=0.01) #lr es la tasa de aprendizaje y weight_decay es la regularización L2\n",
    "\n",
    "\n",
    "\n",
    "print(\"Pesos personalizados de las clases:\")\n",
    "for i, weight in enumerate(class_weights):\n",
    "    print(f\"Clase {i}: {weight.item():.4f}\")\n",
    "\n",
    "# print(criterion)\n",
    "\n",
    "# Función de entrenamiento\n",
    "def train(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for embeddings, labels in tqdm(dataloader):\n",
    "        embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(embeddings)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "# Función de evaluación\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for embeddings, labels in tqdm(dataloader):\n",
    "            embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "            outputs = model(embeddings)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_predictions.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_predictions, average='weighted')\n",
    "    accuracy = sum(1 for x,y in zip(all_predictions, all_labels) if x == y) / len(all_labels)\n",
    "    \n",
    "    return avg_loss, accuracy, precision, recall, f1\n",
    "\n",
    "# Función de early stopping\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss == None:\n",
    "            self.best_loss = val_loss\n",
    "        elif self.best_loss - val_loss > self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        elif self.best_loss - val_loss < self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "\n",
    "# Entrenamiento con early stopping opcional y medición de tiempo\n",
    "num_epochs = 100 # Número máximo de épocas\n",
    "use_early_stopping = True  # Cambia a False para desactivar early stopping\n",
    "early_stopping = EarlyStopping(patience=8, min_delta=0.001) if use_early_stopping else None\n",
    "\n",
    "start_time = time.time()\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_start_time = time.time()\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "    train_loss = train(model, train_loader, criterion, optimizer, device)\n",
    "    train_losses.append(train_loss)\n",
    "    print(f'Training loss: {train_loss:.4f}')\n",
    "    \n",
    "    val_loss, val_accuracy, val_precision, val_recall, val_f1 = evaluate(model, val_loader, criterion, device)\n",
    "\n",
    "    val_losses.append(val_loss)\n",
    "    print(f'Validation loss: {val_loss:.4f}')\n",
    "    print(f'Validation Accuracy: {val_accuracy:.4f}')\n",
    "    print(f'Validation Precision: {val_precision:.4f}')\n",
    "    print(f'Validation Recall: {val_recall:.4f}')\n",
    "    print(f'Validation F1-score: {val_f1:.4f}')\n",
    "    \n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    print(f'Epoch time: {epoch_time:.2f} seconds')\n",
    "\n",
    "    if use_early_stopping:\n",
    "        early_stopping(val_loss)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f'Total training time: {total_time:.2f} seconds')\n",
    "\n",
    "#Evaluación final en el conjunto de prueba\n",
    "test_loss, test_accuracy, test_precision, test_recall, test_f1 = evaluate(model, test_loader, criterion, device)\n",
    "print('Test Results:')\n",
    "print(f'Test loss: {test_loss:.4f}')\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "print(f'Test Precision: {test_precision:.4f}')\n",
    "print(f'Test Recall: {test_recall:.4f}')\n",
    "print(f'Test F1-score: {test_f1:.4f}')\n",
    "\n",
    "# Guardar el modelo\n",
    "torch.save(model.state_dict(), 'bert_embedding_classifier_smote_false.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asumimos que tienes estas listas con los valores de pérdida para cada época\n",
    "epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, train_losses, 'b', label='Pérdida de entrenamiento')\n",
    "plt.plot(epochs, val_losses, 'r', label='Pérdida de validación')\n",
    "plt.title('Curva de Aprendizaje')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Guardar la figura\n",
    "plt.savefig('curva_aprendizaje.png')\n",
    "\n",
    "# Mostrar la figura\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CALCULO DEL MACRO F1 SCORE Y LIE F1 SCORE\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for embeddings, labels in tqdm(dataloader):\n",
    "            embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "            outputs = model(embeddings)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_predictions.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_predictions, average='weighted')\n",
    "    accuracy = sum(1 for x,y in zip(all_predictions, all_labels) if x == y) / len(all_labels)\n",
    "    \n",
    "    # Calcular el Macro F1 score\n",
    "    macro_f1 = f1_score(all_labels, all_predictions, average='macro')\n",
    "    \n",
    "    # Calcular el Lie F1 score (asumiendo que la clase de mentiras es 1)\n",
    "    lie_f1 = f1_score(all_labels, all_predictions, pos_label=1)\n",
    "    \n",
    "    return avg_loss, accuracy, precision, recall, f1, macro_f1, lie_f1\n",
    "\n",
    "val_loss, val_accuracy, val_precision, val_recall, val_f1, val_macro_f1, val_lie_f1 = evaluate(model, val_loader, criterion, device)\n",
    "print(f'Validation Macro F1-score: {val_macro_f1:.4f}')\n",
    "print(f'Validation Lie F1-score: {val_lie_f1:.4f}')\n",
    "\n",
    "test_loss, test_accuracy, test_precision, test_recall, test_f1, test_macro_f1, test_lie_f1 = evaluate(model, test_loader, criterion, device)\n",
    "print(f'Test Macro F1-score: {test_macro_f1:.4f}')\n",
    "print(f'Test Lie F1-score: {test_lie_f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FIN DEL CÓDIGO ###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
